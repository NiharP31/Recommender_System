# -*- coding: utf-8 -*-
"""Recommendation_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t11SyvWSbSLf4k9Q3t3DpZBzg17K-Ta2

Importing dataset
"""

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/BX-Books.csv',error_bad_lines=False,encoding='latin-1',sep=';')
df.head()

df.info()

"""Removing diplicates as this are redundant to the algorithm and must be removed."""

df.duplicated(subset='Book-Title').sum()

df = df.drop_duplicates(subset='Book-Title')

df.duplicated(subset='Book-Title').sum()

"""Randomly Sampling 15000 rows from 271k rows. Chosen size is 15k to avoid running into memory errors."""

sample_size = 15000
df = df.sample(n=sample_size,replace=False,random_state=490)
df = df.reset_index() #reset index is used to reset the index values from 0,1,2....
df.drop('index',axis=1)

df.head()

"""The dataframe contains many columns which are of no use such as ISBN code, YOP,etc. We will only use the "Book-Title","Book-Author",and "Publisher" columns to build the model

We will use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to convert text into its numeric representation before we can apply predictive modeling techniques to it.

Countvectorizer counts each word with equal importance. The white spaces between names should be removed else it will count the authors first and last name as seperate word.

For eg: carl anderson and carl smith both have same name so recommender system might consider the books as highly similar, though the content of both the authors is different.
"""

def clean_text(author):
    result = str(author).lower() #converting the name in lower case
    return(result.replace(' ','')) # replacing the white spaces between the authors name.

df['Book-Author'] = df['Book-Author'].apply(clean_text)

df.head()

df['Book-Author'] = df['Book-Title'].str.lower()
df['Publisher'] = df['Publisher'].str.lower()

"""Finally let's combine these three columns to create a single variable. For that we will drop all the unnecessary columns from the dataframe."""

df2 = df.drop(['ISBN','Image-URL-S','Image-URL-M','Image-URL-L','Year-Of-Publication'],axis=1)

df2['data'] = df2[df2.columns[1:]].apply(lambda x: ' '.join(x.dropna().astype(str)),axis=1)
print(df2['data'].head())

"""Finally applying the skikit-learn's CountVectorizer() on the new combined text-data"""

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()
vectorized = vectorizer.fit_transform(df2['data'])

"""[Cosine Similarity](https://analyticsindiamag.com/cosine-similarity-in-machine-learning/#:~:text=Cosine%20similarity%20is%20used%20as,of%20texts%20in%20the%20document.): It is a metric that calculates the cosine of the angle between two or more vectors to determine if they are pointing in the same direction. 
0 -> two vectors are not similar.
1 -> two vectors are identical.
"""

from sklearn.metrics.pairwise import cosine_similarity

similarities = cosine_similarity(vectorized)

print(similarities)

df = pd.DataFrame(similarities,columns = df['Book-Title'], index=df['Book-Title']).reset_index()

df.head()

input_book = 'Norby and the Oldest Dragon'
recommendations = pd.DataFrame(df.nlargest(11,input_book)['Book-Title'])
recommendations = recommendations[recommendations['Book-Title']!=input_book]
print(recommendations)

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# %pip install transformers

import streamlit as st
from transformers import pipeline

st.title('Books Recommender System')
st.markdown('This is a recommender system designed using parameters such as Cosine Similarity, Count Vectorizer. The input is taken as book name and the output is a recommendation related to similar search.')

def run():
  with st.form(key='Enter Book Name'):
    search_words = st.text_input('Enter the Book name for which you want similar recommendations')
    number_of_recommendations = st.number_input('Enter the number of books recommendation which you want to know (Maximum 50 books)', 0,50,10)
    submit_button = st.form_submit_button(label='Submit')
    if submit_button:
      recommendations = pd.DataFrame.items(number_of_recommendations)
      Rs_list = [i.text for i in recommendations]
      df3 = pd.DataFrame(columns =['Latest'+str(number_of_recommendations)+'Tweets'+' on '+search_words, 'sentiment'])
      st.write(df3)

